{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_core in ./venv/lib/python3.12/site-packages (0.3.43)\n",
      "Requirement already satisfied: langchain_ollama in ./venv/lib/python3.12/site-packages (0.2.3)\n",
      "Requirement already satisfied: dotenv in ./venv/lib/python3.12/site-packages (0.9.9)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in ./venv/lib/python3.12/site-packages (from langchain_core) (0.3.13)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./venv/lib/python3.12/site-packages (from langchain_core) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.12/site-packages (from langchain_core) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.12/site-packages (from langchain_core) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./venv/lib/python3.12/site-packages (from langchain_core) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./venv/lib/python3.12/site-packages (from langchain_core) (4.12.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in ./venv/lib/python3.12/site-packages (from langchain_core) (2.10.6)\n",
      "Requirement already satisfied: ollama<1,>=0.4.4 in ./venv/lib/python3.12/site-packages (from langchain_ollama) (0.4.7)\n",
      "Requirement already satisfied: python-dotenv in ./venv/lib/python3.12/site-packages (from dotenv) (1.0.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain_core) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain_core) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain_core) (3.10.15)\n",
      "Requirement already satisfied: requests<3,>=2 in ./venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain_core) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain_core) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain_core) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.2->langchain_core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.2->langchain_core) (2.27.2)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_core) (4.8.0)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_core) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_core) (1.0.7)\n",
      "Requirement already satisfied: idna in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_core) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_core) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain_core) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain_core) (2.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./venv/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_core) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain_core langchain_ollama dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.2\")  # Use the appropriate model name for your Ollama setup\n",
    "# llm.invoke(\"Tell me a joke about bears!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, so I need to tell someone a joke about bears. Hmm, let\\'s think about how to make it fun and appropriate. First, I should consider the audience—probably kids or maybe adults who like humor. Bears are interesting animals, but they can be a bit tricky for some people because they\\'re often seen as tough or difficult.\\n\\nI want the joke to be light-hearted and maybe a little funny without being offensive. Maybe something that plays on a common stereotype about bears. I remember hearing somewhere that bears are lazy, not efficient. So, perhaps using that as the punchline could work. \\n\\nLet me think of the structure. Jokes usually have an opening setup, a question or statement leading to the punchline, and then a resolution. Maybe something like, \"Why don\\'t bears enjoy ice cream? Because...\" Then, I need a pun here.\\n\\nOh, wait! There\\'s a play on words with \"enjoy.\" Polar bears can say \"I love it\" because they love polar coordinates—polar being related to the coordinate system and love for the pole. That might work well. Let me put that together.\\n\\nSo, starting with the setup: \"Why don\\'t bears enjoy ice cream?\" Then, leading into the pun: because polar bears love polar coordinates, which is like saying they love polar! Finally, a play on words to make it humorous. Maybe something like \"I love to dance in my room\" or another pun related to coordinates.\\n\\nPutting it all together:\\n\\nWhy don\\'t bears enjoy ice cream?\\nBecause polar bears love polar coordinates,\\nWhich is like saying they love polar!\\n\\nThat seems to fit well. It uses the humor of being lazy and the pun on polar bears\\' interest in coordinate systems, which are polar coordinates. The playful ending with dancing ties it back to the theme of movement.\\n</think>\\n\\nWhy don\\'t bears enjoy ice cream?  \\nBecause polar bears love polar coordinates,  \\nWhich is like saying they love polar!', additional_kwargs={}, response_metadata={'model': 'deepseek-r1:1.5b', 'created_at': '2025-03-11T09:40:02.454099269Z', 'done': True, 'done_reason': 'stop', 'total_duration': 24986323228, 'load_duration': 1298930402, 'prompt_eval_count': 10, 'prompt_eval_duration': 236000000, 'eval_count': 400, 'eval_duration': 23448000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-8b0e30cf-3902-417b-a256-aa8e38a32c81-0', usage_metadata={'input_tokens': 10, 'output_tokens': 400, 'total_tokens': 410})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "llm.invoke([\n",
    "    HumanMessage(\"Tell me a joke about bears!\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "joke_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a world class comedian.\"),\n",
    "    (\"human\", \"Tell me a joke about {topic}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a world class comedian.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Tell me a joke about beets', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joke_prompt.invoke({\"topic\": \"beets\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = joke_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, so I\\'m trying to come up with a joke about beets. I know that beet leapers are those funny animals who jump out of the water after eating too much bread. But how can I turn that into a joke? Maybe I need to play around with the idea of a beeter and their reaction when they eat something really heavy.\\n\\nFirst, I should think about what makes beet leapers funny. They\\'re so unpredictable in behavior. So maybe the joke revolves around their reactions. Perhaps using the idea that if you feed them too much bread, it\\'s like feeding a beeter with butter. But wait, that doesn\\'t make sense because beets are plants and don\\'t eat butter.\\n\\nWait, that might not work. Maybe I can take the metaphor of the beeter and apply it to something else. Instead of beet leapers eating bread, maybe they\\'re eating something heavy like cheese or meat. Or perhaps using a different type of food altogether. \\n\\nAlternatively, maybe the joke is about the beeter being too picky or hard on someone. For example, if you give them too much attention, they might jump out of nowhere. But I need to make that into a playful joke.\\n\\nI also remember hearing that beet leapers can jump out of water after eating a lot of bread because it\\'s like their way of deflating. So maybe the joke is about what happens when they eat something unexpected. \\n\\nLet me think: if a beeter eats something heavy, like nuts or seeds, would they react similarly to how beet leapers react? Maybe jumping out of water again. That could lead to a pun between \"beeter\" and \"beetle.\" Or perhaps it\\'s about the beeter being too picky with someone else.\\n\\nAnother angle: since beet leapers can jump from any height after eating bread, maybe the joke is about how a beeter might leap over something, like a chair or table. That could add a funny element to their behavior.\\n\\nI also need to make sure that the humor isn\\'t too obvious and fits well within the context of the topic. It should be something that\\'s playful and not just a straightforward pun but somehow ties into the nature of beet leapers.\\n\\nMaybe combining both ideas: if you feed them enough to like butter, they might jump out of the water again because it\\'s similar to how they react when eating bread. That could lead to a joke about the beeter reacting to butter in the same way they react to bread.\\n\\nI should also consider using a pun with \"beeter\" and \"beetle.\" For example, saying that a beeter might jump out of a table because it\\'s too picky with someone else. That ties both concepts together humorously.\\n\\nOverall, I think focusing on the unpredictability of beet leaper behavior and using their reaction to food is key. Maybe combining that with a pun between \"beeter\" and \"beetle\" would create an engaging joke.\\n</think>\\n\\nHere’s a cleverly crafted joke that combines the unpredictability of beet leapers with a fun pun:\\n\\n**Beeter than a beeter?**\\n\\n**A beeter might leap out of a table because it\\'s too picky with someone else.** That\\'s as unexpected and playful as you can get about beet leaper behavior!', additional_kwargs={}, response_metadata={'model': 'deepseek-r1:1.5b', 'created_at': '2025-03-11T10:11:02.588298588Z', 'done': True, 'done_reason': 'stop', 'total_duration': 43478443282, 'load_duration': 1794824542, 'prompt_eval_count': 17, 'prompt_eval_duration': 596000000, 'eval_count': 674, 'eval_duration': 40596000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-362f1a66-0f12-4d9a-b998-75781d260d36-0', usage_metadata={'input_tokens': 17, 'output_tokens': 674, 'total_tokens': 691})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topic\": \"beets\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "str_chain = chain | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nAlright, so I\\'m trying to come up with a joke about beets. Hmm, beets aren\\'t as commonly associated with humor as some other plants or animals. They grow in the fall, right? So maybe they don\\'t have much in common with people who like to get drunk at night.\\n\\nLet me think about how beets are usually handled. They can be tender, so maybe I can play on that. Like, when you cut a beet, it\\'s tender, and sometimes people cut it like a dog. Maybe that\\'s part of the joke. \\n\\nI also wonder if there\\'s anything about beet juice or something that can get drunk with. Beet juice is sweet, and it often gets drunk at parties or receipts. That could be another angle. So maybe I can joke about people drinking beet juice.\\n\\nPutting those together: when you cut a beet like a dog ( tender ), and people drink beet juice ( sweet ) to get drunk. That seems like a good setup for the joke.\\n\\nNow, how do I make that into a proper joke? Maybe start by saying something like cutting a beet isn\\'t so bad because it\\'s tender—like how dogs are kind of cut thin. Then add the other part: people who drink beets can get drunk with beet juice.\\n\\nWait, but is that accurate? Beet juice can have some tangy taste too, which might not fit well. Maybe I should phrase it differently. Alternatively, think about something more unrelated to drinks but still ties into beet characteristics.\\n\\nPerhaps instead of beet juice, use something like a sweetie or another sweetenset substance. So the joke could be: Cutting a sweetie isn\\'t so bad as cutting a dog—both are tender—and people who drink sweeties can get drunk with them because they\\'re sweet. That way, it\\'s more general and still ties back to beet characteristics.\\n\\nYeah, that seems better. It uses the idea of being tender and then connects it to something that can be drunk, which is sweet.\\n</think>\\n\\nWhen you cut a sweetie—think of how a dog cuts through tender flesh—it’s nothing to fear because both are tender. Just like cutting a beet or a sweetie, people who drink them, which are actually sweet, can get drunk with the tangy or sweet flavors. So, here\\'s your joke: \"Cutting a sweetie isn\\'t so bad as cutting a dog—both are tender—and people who drink sweeties can get drunk with them because they\\'re sweet.\"'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_chain.invoke({\"topic\": \"beets\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"<think>\\n\\n</think>\\n\\nHi there! I suggest getting online to get real-time information. If you have any other questions, please don't hesitate to let me know!\", additional_kwargs={}, response_metadata={'model': 'deepseek-r1:1.5b', 'created_at': '2025-03-11T15:11:19.505802136Z', 'done': True, 'done_reason': 'stop', 'total_duration': 6020946016, 'load_duration': 3581785323, 'prompt_eval_count': 9, 'prompt_eval_duration': 200000000, 'eval_count': 34, 'eval_duration': 2237000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-0532b5e6-ba1b-4f64-acd5-5c83cf03434d-0', usage_metadata={'input_tokens': 9, 'output_tokens': 34, 'total_tokens': 43})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is the current date?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I was told the current date is \"2024-12-31\" but I am not aware of the current time or any updates after this information was given to me.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", 'You know that the current date is \"{current_date}\".'),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "chain.invoke({\n",
    "    \"question\": \"What is the current date?\",\n",
    "    \"current_date\": date.today()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Old Ship Saloon's total revenue in Q3 2023 was $474,773.38.\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SOURCE = \"\"\"\n",
    "Old Ship Saloon 2023 quarterly revenue numbers:\n",
    "Q1: $174782.38\n",
    "Q2: $467372.38\n",
    "Q3: $474773.38\n",
    "Q4: $389289.23\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", 'You are a helpful assistant. Use the following context when responding:\\n\\n{context}.'),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "rag_chain = rag_prompt | llm | StrOutputParser()\n",
    "\n",
    "rag_chain.invoke({\n",
    "    \"question\": \"What was the Old Ship Saloon's total revenue in Q3 2023?\",\n",
    "    \"context\": SOURCE\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in ./venv/lib/python3.12/site-packages (0.3.20)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.41 in ./venv/lib/python3.12/site-packages (from langchain) (0.3.43)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in ./venv/lib/python3.12/site-packages (from langchain) (0.3.6)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in ./venv/lib/python3.12/site-packages (from langchain) (0.3.13)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./venv/lib/python3.12/site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./venv/lib/python3.12/site-packages (from langchain) (2.0.38)\n",
      "Requirement already satisfied: requests<3,>=2 in ./venv/lib/python3.12/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.12/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./venv/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./venv/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./venv/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./venv/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain) (3.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./venv/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# debugging\n",
    "%pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [4ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You know that the current date is \\\"2025-03-11\\\".\\nHuman: What is the current date?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] [12.05s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"I was told the knowledge cutoff is December 2023, but I don't have have access to real-time information. My previous statement about the current date being \\\"2025-03-11\\\" was an error. I can only provide information up to my knowledge cutoff in December 2023.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2\",\n",
      "          \"created_at\": \"2025-03-11T15:41:10.258005226Z\",\n",
      "          \"done\": true,\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"total_duration\": 12038394979,\n",
      "          \"load_duration\": 2807786725,\n",
      "          \"prompt_eval_count\": 46,\n",
      "          \"prompt_eval_duration\": 2274000000,\n",
      "          \"eval_count\": 61,\n",
      "          \"eval_duration\": 6387000000,\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\",\n",
      "            \"images\": null,\n",
      "            \"tool_calls\": null\n",
      "          }\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"I was told the knowledge cutoff is December 2023, but I don't have have access to real-time information. My previous statement about the current date being \\\"2025-03-11\\\" was an error. I can only provide information up to my knowledge cutoff in December 2023.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2\",\n",
      "              \"created_at\": \"2025-03-11T15:41:10.258005226Z\",\n",
      "              \"done\": true,\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"total_duration\": 12038394979,\n",
      "              \"load_duration\": 2807786725,\n",
      "              \"prompt_eval_count\": 46,\n",
      "              \"prompt_eval_duration\": 2274000000,\n",
      "              \"eval_count\": 61,\n",
      "              \"eval_duration\": 6387000000,\n",
      "              \"message\": {\n",
      "                \"lc\": 1,\n",
      "                \"type\": \"not_implemented\",\n",
      "                \"id\": [\n",
      "                  \"ollama\",\n",
      "                  \"_types\",\n",
      "                  \"Message\"\n",
      "                ],\n",
      "                \"repr\": \"Message(role='assistant', content='', images=None, tool_calls=None)\"\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-da949f9b-412f-4f02-afbf-47b4ea63e8bc-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 46,\n",
      "              \"output_tokens\": 61,\n",
      "              \"total_tokens\": 107\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"I was told the knowledge cutoff is December 2023, but I don't have have access to real-time information. My previous statement about the current date being \\\"2025-03-11\\\" was an error. I can only provide information up to my knowledge cutoff in December 2023.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [12.06s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"I was told the knowledge cutoff is December 2023, but I don't have have access to real-time information. My previous statement about the current date being \\\"2025-03-11\\\" was an error. I can only provide information up to my knowledge cutoff in December 2023.\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I was told the knowledge cutoff is December 2023, but I don\\'t have have access to real-time information. My previous statement about the current date being \"2025-03-11\" was an error. I can only provide information up to my knowledge cutoff in December 2023.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.globals import set_debug\n",
    "\n",
    "set_debug(True)\n",
    "\n",
    "from datetime import date\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", 'You know that the current date is \"{current_date}\".'),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "chain.invoke({\n",
    "    \"question\": \"What is the current date?\",\n",
    "    \"current_date\": date.today()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_chain_start', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'name': 'RunnableSequence', 'tags': [], 'metadata': {}, 'data': {'input': {'question': 'What is the current date?', 'current_date': datetime.date(2025, 3, 11)}}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_prompt_start', 'name': 'ChatPromptTemplate', 'run_id': '3cb9f990-04b6-4ff8-9469-1622e0fdab4c', 'tags': ['seq:step:1'], 'metadata': {}, 'data': {'input': {'question': 'What is the current date?', 'current_date': datetime.date(2025, 3, 11)}}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_prompt_end', 'name': 'ChatPromptTemplate', 'run_id': '3cb9f990-04b6-4ff8-9469-1622e0fdab4c', 'tags': ['seq:step:1'], 'metadata': {}, 'data': {'input': {'question': 'What is the current date?', 'current_date': datetime.date(2025, 3, 11)}, 'output': ChatPromptValue(messages=[SystemMessage(content='You know that the current date is \"2025-03-11\".', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the current date?', additional_kwargs={}, response_metadata={})])}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_start', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'input': {'messages': [[SystemMessage(content='You know that the current date is \"2025-03-11\".', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the current date?', additional_kwargs={}, response_metadata={})]]}}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content='I', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_start', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': 'I'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': 'I'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' was', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' was'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' was'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' given', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' given'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' given'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' a'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' a'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' specific', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' specific'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' specific'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' date', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' date'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' date'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' in'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' in'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' our', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' our'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' our'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' knowledge', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' knowledge'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' knowledge'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' cutoff', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' cutoff'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' cutoff'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ','}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ','}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' but', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' but'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' but'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' I', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' I'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' I'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' don', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' don'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' don'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=\"'t\", additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': \"'t\"}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': \"'t\"}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' have'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' have'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' real', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' real'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' real'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content='-time', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': '-time'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': '-time'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' access', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' access'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' access'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' to'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' to'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' the'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' the'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' current', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' current'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' current'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' date', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' date'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' date'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': '.'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': '.'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' The'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' The'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' date', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' date'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' date'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' \"', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' \"'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' \"'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content='202', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': '202'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': '202'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content='5', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': '5'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': '5'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': '-'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': '-'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content='03', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': '03'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': '03'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': '-'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': '-'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content='11', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': '11'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': '11'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content='\"', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': '\"'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': '\"'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' was', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' was'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' was'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' provided', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' provided'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' provided'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' to'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' to'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' me', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' me'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' me'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' as', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' as'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' as'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' a'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' a'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' knowledge', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' knowledge'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' knowledge'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' cutoff', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' cutoff'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' cutoff'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' date', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' date'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' date'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ','}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ','}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' but', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' but'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' but'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' it', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' it'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' it'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=\"'s\", additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': \"'s\"}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': \"'s\"}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' not', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' not'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' not'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' necessarily', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' necessarily'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' necessarily'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' the'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' the'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' current', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' current'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' current'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' date', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' date'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' date'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': '.'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': '.'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' If', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' If'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' If'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' you', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' you'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' you'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' need', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' need'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' need'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' to'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' to'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' know', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' know'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' know'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' the'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' the'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' current', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' current'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' current'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' date', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' date'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' date'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ','}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ','}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' I', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' I'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' I'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' recommend', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' recommend'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' recommend'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' checking', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' checking'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' checking'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' a'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' a'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' reliable', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' reliable'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' reliable'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' online', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' online'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' online'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' source', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' source'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' source'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' or', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' or'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' or'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' your', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' your'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' your'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' device', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' device'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' device'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=\"'s\", additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': \"'s\"}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': \"'s\"}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' clock', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' clock'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' clock'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' for', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' for'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' for'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' the'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' the'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' most', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' most'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' most'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' up', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' up'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' up'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content='-to', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': '-to'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': '-to'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content='-date', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': '-date'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': '-date'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content=' information', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ' information'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ' information'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-28cf56ff-d4fa-412e-823e-309f98269437')}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': '.'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': '.'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOllama', 'run_id': '28cf56ff-d4fa-412e-823e-309f98269437', 'tags': ['seq:step:2'], 'metadata': {'ls_provider': 'ollama', 'ls_model_name': 'llama3.2', 'ls_model_type': 'chat', 'ls_temperature': None}, 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-03-11T15:48:08.091608661Z', 'done': True, 'done_reason': 'stop', 'total_duration': 14941779193, 'load_duration': 2554240265, 'prompt_eval_count': 46, 'prompt_eval_duration': 2415000000, 'eval_count': 83, 'eval_duration': 9399000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-28cf56ff-d4fa-412e-823e-309f98269437', usage_metadata={'input_tokens': 46, 'output_tokens': 83, 'total_tokens': 129})}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_stream', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'chunk': ''}, 'parent_ids': []}\n",
      "-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NotImplementedError in LogStreamCallbackHandler.on_llm_end callback: NotImplementedError('Trying to load an object that doesn\\'t implement serialization: {\\'lc\\': 1, \\'type\\': \\'not_implemented\\', \\'id\\': [\\'ollama\\', \\'_types\\', \\'Message\\'], \\'repr\\': \"Message(role=\\'assistant\\', content=\\'\\', images=None, tool_calls=None)\"}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_chain_stream', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'name': 'RunnableSequence', 'data': {'chunk': ''}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_parser_end', 'name': 'StrOutputParser', 'run_id': '4c277cc7-052e-42dc-9e9c-49f4bc3bce89', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'input': AIMessageChunk(content='I was given a specific date in our knowledge cutoff, but I don\\'t have real-time access to the current date. The date \"2025-03-11\" was provided to me as a knowledge cutoff date, but it\\'s not necessarily the current date. If you need to know the current date, I recommend checking a reliable online source or your device\\'s clock for the most up-to-date information.', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-03-11T15:48:08.091608661Z', 'done': True, 'done_reason': 'stop', 'total_duration': 14941779193, 'load_duration': 2554240265, 'prompt_eval_count': 46, 'prompt_eval_duration': 2415000000, 'eval_count': 83, 'eval_duration': 9399000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-28cf56ff-d4fa-412e-823e-309f98269437', usage_metadata={'input_tokens': 46, 'output_tokens': 83, 'total_tokens': 129}), 'output': 'I was given a specific date in our knowledge cutoff, but I don\\'t have real-time access to the current date. The date \"2025-03-11\" was provided to me as a knowledge cutoff date, but it\\'s not necessarily the current date. If you need to know the current date, I recommend checking a reliable online source or your device\\'s clock for the most up-to-date information.'}, 'parent_ids': []}\n",
      "-----\n",
      "{'event': 'on_chain_end', 'name': 'RunnableSequence', 'run_id': '9bd11218-d1a2-43bb-b4df-08f1ef835de7', 'tags': [], 'metadata': {}, 'data': {'output': 'I was given a specific date in our knowledge cutoff, but I don\\'t have real-time access to the current date. The date \"2025-03-11\" was provided to me as a knowledge cutoff date, but it\\'s not necessarily the current date. If you need to know the current date, I recommend checking a reliable online source or your device\\'s clock for the most up-to-date information.'}, 'parent_ids': []}\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# Turn off debug mode for clarity\n",
    "set_debug(False)\n",
    "\n",
    "stream = chain.astream_events({\n",
    "    \"question\": \"What is the current date?\",\n",
    "    \"current_date\": date.today()\n",
    "}, version=\"v1\")\n",
    "\n",
    "async for event in stream:\n",
    "    print(event)\n",
    "    print(\"-----\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
